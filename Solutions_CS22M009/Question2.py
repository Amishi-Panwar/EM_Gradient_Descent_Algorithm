# -*- coding: utf-8 -*-
"""Que2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jzb3aKuDAm5dZ211DApNifeqIkqFszDP

**Assignment 2**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from numpy.linalg import inv

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive/My\ Drive

#load data points
df_train = pd.read_csv("Assignment PRML/A2Q2Data_train.csv",header=None)
data_points=df_train.shape[0]

#seperate out last column which gives y value
X_train = df_train.iloc[:, :-1]
Y_train = df_train.iloc[:, -1]

#make the features verticle
X_train = np.array(X_train.T)
Y_train = np.array(Y_train.T)

"""**Quetion.2 Part-(i)**"""
#calculate wml
wml= np.matmul(np.matmul(inv(np.matmul(X_train, X_train.T)),X_train),Y_train)
print(wml)

"""**Quetion.2 Part-(ii)**"""

def gradient_descent(X_train, Y_train):
  #initialize w randomly
  l=X_train.shape[1]
  rand_index=np.random.randint(0,l-1);
  w=X_train[:,rand_index]
  w=np.array(w)

  #calculate X*X_transpose
  X_XT=np.matmul(X_train,X_train.T)
  #calculate X*Y
  X_Y=np.matmul(X_train,Y_train)

  itr=1
  iterations=[]
  #list to append w in all iterations till convergence
  all_ws=[]
  all_ws.append(w)
  iterations.append(itr)
  threshold=1e-2
  while True:
    w_new=w-(1e-6/(itr))*(2*np.matmul(X_XT,w)-2*X_Y)

    #calculate error b/w new and prev w
    diff=w_new-w
    error=np.sqrt(np.dot(diff.T,diff))

    #if error is less than threshold -> break, else continue with new w
    if(error<=threshold):
      break;
    all_ws.append(w_new)
    itr+=1
    iterations.append(itr)
    #assign new w to prev w
    w=w_new
    
  np.array(all_ws)
  return all_ws, iterations

all_ws, iterations = gradient_descent(X_train, Y_train)

#calculate distance of ws from wml 
def norm2_wt_wml(all_ws):
  diff_with_wml=[]
  for i in range(0,len(all_ws)):
    diff_with_wml.append(all_ws[i]-wml)

  diff_with_wml=np.array(diff_with_wml)
  error_plot=[]
  for i in range(0,len(all_ws)):
    dot_product=np.dot(diff_with_wml[i].T,diff_with_wml[i])
    error_plot.append(np.sqrt(dot_product))
  return error_plot

error_plot = norm2_wt_wml(all_ws)

plt.title('Plot of norm2(wt-wml)')
plt.xlabel('Iterations')
plt.ylabel('norm2(wt-wml)')
plt.plot(iterations,error_plot)
plt.show()

"""**Quetion.2 Part-(iii)**"""

#make batches of 100 random data points
def make_batch_of_100():
  rand_index=[]
  for i in range(0,100):
    rand_index.append(np.random.randint(0,9999))
  X_train_batch = []
  Y_train_batch = []
  for i in range(0,100):
    X_train_batch.append(X_train[:,rand_index[i]])
    Y_train_batch.append(Y_train[rand_index[i]])
  X_train_batch = np.array(X_train_batch)
  Y_train_batch = np.array(Y_train_batch)
  return X_train_batch, Y_train_batch

X_train_batch, Y_train_batch = make_batch_of_100()

def gradient_descent(X_train, Y_train, w):
  X_XT=np.matmul(X_train,X_train.T)
  X_Y=np.matmul(X_train,Y_train)
  itr=1
  iterations=[]
  all_ws=[]
  all_ws.append(w)
  iterations.append(itr)
  threshold=1e-2
  while True:
    w_new=w-(1e-6/(itr))*(2*np.matmul(X_XT,w)-2*X_Y)
    diff=w_new-w
    error=np.sqrt(np.dot(diff.T,diff))
    if(error<=threshold):
      break;
    all_ws.append(w_new)
    itr+=1
    iterations.append(itr)
    w=w_new
  #return converged w
  return w_new, iterations

w_batch=[]
iteration_batch=[]
rand_index=np.random.randint(0,9999);
#initialize w with random values
w = X_train[:,rand_index]
w = np.array(w)
for i in range(0, 1000):
  X_train_batch, Y_train_batch = make_batch_of_100()
  ws, itrs = gradient_descent(X_train_batch, Y_train_batch ,w)
  w_batch.append(np.array(ws))
  iteration_batch.append(i)
  w = ws

def norm2_wt_wml(all_ws):
  diff_with_wml=[]
  for i in range(0,len(all_ws)):
    diff_with_wml.append(all_ws[i]-wml)

  diff_with_wml=np.array(diff_with_wml)
  error_plot=[]

  for i in range(0,len(all_ws)):
    dot_product=np.dot(diff_with_wml[i].T,diff_with_wml[i])
    error_plot.append(np.sqrt(dot_product))
  return error_plot

error_plot = norm2_wt_wml(w_batch)

plt.title('Plot of norm2(wt-wml)')
plt.xlabel('Iterations')
plt.ylabel('norm2(wt-wml)')
plt.plot(iteration_batch,error_plot)
plt.show()

sochastic_w = np.average(w_batch, axis = 0)
print(sochastic_w)

"""**Quetion.2 Part-(iv)**"""

X = X_train[:, :-2000]
Y = Y_train[ :-2000]
X_validate = X_train[:, 8000:]
Y_validate = Y_train[8000:]

print(X_validate.shape)
print(Y_validate.shape)
print(X.shape)
print(Y.shape)

def gradient_descent(X_train, Y_train, tolerance,lambda_):
  l=X_train.shape[1]
  rand_index=np.random.randint(0,l-1);
  w=X_train[:,rand_index]
  w=np.array(w)
  X_XT=np.matmul(X_train,X_train.T)
  X_Y=np.matmul(X_train,Y_train)
  itr=1
  iterations=[]
  all_ws=[]
  all_ws.append(w)
  iterations.append(itr)
  while True:
    w_new=w-(1e-6/(itr))*(2*np.matmul(X_XT,w)-2*X_Y+2*lambda_*w)
    diff=w_new-w
    error=np.sqrt(np.dot(diff.T,diff))
    if(error<=tolerance):
      break;
    all_ws.append(w_new)
    itr+=1
    iterations.append(itr)
    w=w_new
  all_ws = np.array(all_ws)
  return w_new, iterations

def cross_validation_for_lambda(X, Y, X_validate, Y_validate):
  #checking over list of lambdas
  lambdas = np.arange(0.01,1.01,0.01)
  errors_list = []
  tolerance = 1e-7

  min_lambda = 0
  for l in lambdas:
    w, iterations = gradient_descent(X, Y, tolerance, l)

    len = X_validate.shape[1]
    error=0;
    for j in range(0,len):
      diff = np.dot(w.T,X_validate[:,j]) - Y_validate[j]
      error += diff*diff
    errors_list.append(error)
  #find lamda which gives min error
  min_lambda = lambdas[errors_list.index(min(errors_list))]
  return lambdas, errors_list, min_lambda

lambdas, errors, min_lambda = cross_validation_for_lambda(X, Y, X_validate, Y_validate)
w_hat = np.matmul(np.matmul(np.linalg.pinv(np.matmul(X,X.T) + min_lambda *np.identity(100)),X),Y)
w_hat = np.array(w_hat)
print(min_lambda)
print(w_hat)

plt.title('Plot of Error v/s Lambda')
plt.xlabel('Lambda')
plt.ylabel('Error')
plt.plot(lambdas,errors)
plt.show()

#load data points
df_test = pd.read_csv("Assignment PRML/A2Q2Data_test.csv",header=None)
df_test.shape

#seperate out last column which gives y value
X_test = df_test.iloc[:, :-1]
Y_test = df_test.iloc[:, -1]

#make the features verticle
X_test = np.array(X_test.T)
Y_test = np.array(Y_test.T)

len = X_test.shape[1]
errorRidge =0
for i in range(0, len):
  errorRidge += pow(np.dot(w_hat.T, X_test[:,i])-Y_test[i], 2)
print(errorRidge)

len = X_test.shape[1]
errorWml =0
for i in range(0, len):
  errorWml += pow(np.dot(wml.T, X_test[:,i])-Y_test[i], 2)
print(errorWml)
